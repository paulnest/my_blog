{
  "hash": "237924b33e05af0276cf702faf17dc7b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analyse comparative de la spectrométrie du saumon de consommation\"\nauthor: \"Paul Nestour\"\ndate: \"2024-05-16\"\ncategories: [Dossier]\nabstract: \"Ce dossier a été rédigé dans le cadre du cours 'Modélisation avec des variables latentes' pendant notre première année de Master ECA.\"\n---\n\n\n## Introduction et démarche\n\nL'étude initiale, issue de la publication \"Data fusion and multivariate analysis for food authenticity analysis\", avait pour objectif d'établir un modèle permettant de déterminer l'authenticité du saumon en fonction de son origine géographique et de son mode d'élevage. Pour ce faire, les chercheurs se sont appuyés sur une base de données constituée de 521 échantillons de saumon provenant de fournisseurs de quatre pays différents (Alaska, Écosse, Norvège et Islande), avec des méthodes de production sauvage ou d'élevage, chaque pays ayant ses spécificités propres.[^1]\n\n[^1]: Hong, Y., Birse, N., Quinn, B., Li, Y., Jia, W., McCarron, P., Wu, D., Rosas da Silva, G., Vanhaecke, L., van Ruth, S., & Elliott, C. T.(2023).Data fusion and multivariate analysis for food authenticity analysis.Nature Communications, 14, Article 3309. https://doi.org/10.1038/s41467-023-38382-z\n\nAinsi, les chercheurs ont utilisé la spectrométrie de masse à plasma à couplage inductif (ICP-MS), une des techniques spectrométriques les plus importantes. Sa sensibilité extrêmement élevée et une large plage dynamique linéaire permettent l'analyse simultanée des composants principaux et des ultra-traces. Cette technique est capable d'analyser des éléments de Li à U et peut être appliquée aux solutions et aux solides. Son utilisation permet donc l’analyse quantitative d'éléments mineurs et est utilisée dans un large panel de processus industriels et agroalimentaires : qualification des matières premières, sécurité des produits, recherche et développement, contrôle de la production, analyse des défaillances, etc.[^2]\n\n[^2]: https://www.euro\\ins.fr/materials-and-engineering-sciences/nos-techniques/icp-ms/\n\nLa démarche suivie dans cette analyse a été méthodique, impliquant plusieurs étapes clés pour aboutir à une interprétation cohérente des résultats. Tout d'abord, une analyse descriptive du jeu de données partiel a été réalisée, comprenant 20 éléments chimiques au lieu des 37 initiaux. Les variables des éléments chimiques ont été renommées et normalisées entre 0 et 1. Cette première analyse consistait en la visualisation des statistiques de base des variables (Min, Q1, médiane, Q3, max et moyenne), de leurs valeurs atypiques ou des potentielles valeurs manquantes, ainsi qu’à l’observation des corrélations entre les variables. Les résultats ont été interprétés pour identifier les tendances et les relations entre les variables.\n\nEnsuite, le jeu de données a été divisé en deux ensembles : un ensemble d'apprentissage et un ensemble de test, en fonction de la variable de classe, et le jeu de test est réservé exclusivement à l'évaluation de la performance du modèle. On a procédé à l'ajustement d'un modèle de prédiction. En parallèle, un modèle PLS-DA a été ajusté en utilisant la méthode des moindres carrés partiels avec une validation croisée à 5 plis. Les résultats de la validation croisée ont été minutieusement analysés pour sélectionner le nombre optimal de composantes latentes. La performance du modèle a été évaluée en termes d'exactitude, de kappa et d'autres métriques, tandis que sa qualité prédictive a été évaluée en utilisant la matrice de confusion, la précision, le rappel et le score F1 sur l'ensemble de test. De plus, les variables importantes pour la discrimination entre les classes ont été identifiées à partir de l'importance des variables dans le modèle PLS-DA. Tous ces résultats ont ensuite été visualisés pour faciliter leur interprétation.\n\nEn conclusion, cette approche méthodique et exhaustive a permis d'explorer et d'analyser en profondeur les données ICP-MS Raw, en mettant en lumière les modèles, les tendances et les relations entre les variables. Les conclusions tirées fournissent une base solide pour comprendre et interpréter les mécanismes sous-jacents ainsi que les facteurs influençant les différentes classes présentes dans les données.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Chargement des packages nécessaires\ninstall.packages(\"lattice\")\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(caret)\nlibrary(pls)\nlibrary(tidyr)\nlibrary(tidyverse)\n\n# Lecture du fichier CSV\nICPMS_Raw_data <- read_csv(\"./ICPMS.csv\")\n\n# Conversion de la variable 'Class' en facteur\nICPMS_Raw_data$Class <- as.factor(ICPMS_Raw_data$Class)\n\n# Sélection des 20 éléments restants\nselected_elements <- c(\"7  Li  [ No Gas ]\", \"11  B  [ No Gas ]\", \"27  Al  [ He ]\", \"51  V  [ He ]\", \"52  Cr  [ He ]\", \"55  Mn  [ He ]\", \"56  Fe  [ He ]\", \"59  Co  [ He ]\", \"60  Ni  [ He ]\", \"63  Cu  [ He ]\", \"66  Zn  [ He ]\", \"75  As  [ He ]\", \"78  Se  [ He ]\", \"85  Rb  [ He ]\", \"88  Sr  [ He ]\", \"93  Nb  [ He ]\", \"95  Mo  [ He ]\", \"111  Cd  [ He ]\", \"133  Cs  [ He ]\", \"181  Ta  [ He ]\")\n\n# Sélectionner les colonnes spécifiées\nselected_data <- ICPMS_Raw_data[, c(\"Class\", selected_elements)]\n\n# Renommer les colonnes\nnames(selected_data)[-1] <- c(\"Li\", \"B\", \"Al\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"As\", \"Se\", \"Rb\", \"Sr\", \"Nb\", \"Mo\", \"Cd\", \"Cs\", \"Ta\")\n\n# Sélection des colonnes\nselected_data <- ICPMS_Raw_data %>%\n  select(Class, all_of(selected_elements)) %>% \n  rename(\n    Li = `7  Li  [ No Gas ]`,\n    B = `11  B  [ No Gas ]`,\n    Al = `27  Al  [ He ]`,\n    V = `51  V  [ He ]`,\n    Cr = `52  Cr  [ He ]`,\n    Mn = `55  Mn  [ He ]`,\n    Fe = `56  Fe  [ He ]`,\n    Co = `59  Co  [ He ]`,\n    Ni = `60  Ni  [ He ]`,\n    Cu = `63  Cu  [ He ]`,\n    Zn = `66  Zn  [ He ]`,\n    As = `75  As  [ He ]`,\n    Se = `78  Se  [ He ]`,\n    Rb = `85  Rb  [ He ]`,\n    Sr = `88  Sr  [ He ]`,\n    Nb = `93  Nb  [ He ]`,\n    Mo = `95  Mo  [ He ]`,\n    Cd = `111  Cd  [ He ]`,\n    Cs = `133  Cs  [ He ]`,\n    Ta = `181  Ta  [ He ]`\n  )\n\n# Sélection des colonnes à normaliser\ncolumns_to_normalize <- c(\"Li\", \"B\", \"Al\", \"V\", \"Cr\", \"Mn\", \"Fe\", \"Co\", \"Ni\", \"Cu\", \"Zn\", \"As\", \"Se\", \"Rb\", \"Sr\", \"Nb\", \"Mo\", \"Cd\", \"Cs\", \"Ta\")\n\n# Création d'une fonction pour la normalisation min-max\nmin_max_normalize <- function(x) {\n  (x - min(x)) / (max(x) - min(x))\n}\n\n# Appliquer la fonction de normalisation min-max à chaque colonne sélectionnée\nnormalized_data <- selected_data %>%\n  mutate(across(all_of(columns_to_normalize), min_max_normalize))\n\n# Nettoyage des données (exemple : supprimer les lignes avec des valeurs manquantes)\nclean_data <- na.omit(normalized_data)\n```\n:::\n\n\n## Statistiques descriptives\n\nLe jeu de données comprend 20 éléments chimiques, pour lesquels des statistiques descriptives ont été calculées. Les valeurs ont été normalisées pour rendre les variables comparables, révélant ainsi des distributions distinctes pour chaque variable. Dans l'ensemble, les distributions semblent être orientées vers le bas, suggérant une concentration relativement faible des éléments chimiques. De plus, il y a une présence notable de valeurs aberrantes potentielles, ce qui peut nécessiter une attention particulière lors de l'analyse.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Statistiques récapitulatives\nsummary(clean_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       Class           Li               B                 Al         \n Alaskan  : 99   Min.   :0.0000   Min.   :0.00000   Min.   :0.00000  \n Iceland-F: 55   1st Qu.:0.1144   1st Qu.:0.06842   1st Qu.:0.02015  \n Iceland-W: 90   Median :0.2045   Median :0.26722   Median :0.03133  \n Norway   :100   Mean   :0.2369   Mean   :0.28434   Mean   :0.05266  \n Scotland :177   3rd Qu.:0.3329   3rd Qu.:0.43481   3rd Qu.:0.05993  \n                 Max.   :1.0000   Max.   :1.00000   Max.   :1.00000  \n       V                 Cr                Mn               Fe         \n Min.   :0.00000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.06583   1st Qu.:0.03273   1st Qu.:0.1294   1st Qu.:0.06713  \n Median :0.10658   Median :0.06286   Median :0.1844   Median :0.10977  \n Mean   :0.12082   Mean   :0.09437   Mean   :0.2096   Mean   :0.14250  \n 3rd Qu.:0.15987   3rd Qu.:0.11733   3rd Qu.:0.2753   3rd Qu.:0.19804  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n       Co               Ni                 Cu                Zn        \n Min.   :0.0000   Min.   :0.000000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.1515   1st Qu.:0.007158   1st Qu.:0.04898   1st Qu.:0.2259  \n Median :0.2765   Median :0.012419   Median :0.08275   Median :0.3912  \n Mean   :0.2809   Mean   :0.034544   Mean   :0.09374   Mean   :0.3831  \n 3rd Qu.:0.3814   3rd Qu.:0.029384   3rd Qu.:0.12014   3rd Qu.:0.5114  \n Max.   :1.0000   Max.   :1.000000   Max.   :1.00000   Max.   :1.0000  \n       As               Se               Rb               Sr         \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.0932   1st Qu.:0.1378   1st Qu.:0.2324   1st Qu.:0.06777  \n Median :0.1697   Median :0.3123   Median :0.3570   Median :0.11029  \n Mean   :0.2188   Mean   :0.3412   Mean   :0.3761   Mean   :0.13182  \n 3rd Qu.:0.2925   3rd Qu.:0.5109   3rd Qu.:0.5108   3rd Qu.:0.17488  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n       Nb                 Mo                Cd                Cs        \n Min.   :0.000000   Min.   :0.00000   Min.   :0.00000   Min.   :0.0000  \n 1st Qu.:0.009093   1st Qu.:0.09524   1st Qu.:0.00578   1st Qu.:0.1252  \n Median :0.021218   Median :0.13810   Median :0.01908   Median :0.2064  \n Mean   :0.052736   Mean   :0.14691   Mean   :0.09101   Mean   :0.2475  \n 3rd Qu.:0.046410   3rd Qu.:0.18095   3rd Qu.:0.15029   3rd Qu.:0.3545  \n Max.   :1.000000   Max.   :1.00000   Max.   :1.00000   Max.   :1.0000  \n       Ta         \n Min.   :0.00000  \n 1st Qu.:0.01732  \n Median :0.03816  \n Mean   :0.07016  \n 3rd Qu.:0.07411  \n Max.   :1.00000  \n```\n\n\n:::\n\n```{.r .cell-code}\n# Boxplots et moyennes des variables numériques \nclean_data |>\n     pivot_longer(\n      cols = where(is.numeric)\n    ) |>\n    ggplot() +\n    aes(y = value) +\n    facet_wrap(~ name, scales = \"free_y\") +\n    geom_boxplot() +\n    theme_light()\n```\n\n::: {.cell-output-display}\n![](UntitledQMD_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n## Analyse des Corrélations\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Corrélations entre les variables\ncor_matrix <- cor(clean_data[, -1]) # Exclure la variable de classe\ncorrplot::corrplot(cor_matrix, method = \"circle\")\n```\n\n::: {.cell-output-display}\n![](UntitledQMD_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Sélectionner les corrélations supérieures à 0.8\nhigh_corr <- which(cor_matrix > 0.8 & cor_matrix < 1, arr.ind = TRUE)\n\n# Afficher les paires de variables corrélées\nhigh_corr_pairs <- data.frame(row = rownames(cor_matrix)[high_corr[,1]],\n                              col = colnames(cor_matrix)[high_corr[,2]],\n                              corr_value = cor_matrix[high_corr])\nhigh_corr_pairs\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  row col corr_value\n1  Se  Zn  0.8192668\n2  Zn  Se  0.8192668\n3  Cs  Rb  0.8668789\n4  Ta  Nb  0.9427543\n5  Rb  Cs  0.8668789\n6  Nb  Ta  0.9427543\n```\n\n\n:::\n:::\n\n\nLes résultats de l’analyse des corrélations suggèrent également qu'il existe des corrélations significatives entre certaines paires de variables. Par exemple, la corrélation des éléments chimiques Se et Zn est de 0.82, celle des éléments chimiques Cs et Rb est de 0.87, et celle des éléments chimiques Ta et Nb est de 0.94. Ces fortes corrélations peuvent indiquer une relation chimique ou géologique commune entre ces éléments. Ces résultats peuvent servir de base pour des analyses plus avancées ou pour formuler des hypothèses à explorer davantage dans notre étude.\n\n## Découpage du Jeu de Données\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Distribution de la variable Class\ntable(clean_data$Class)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  Alaskan Iceland-F Iceland-W    Norway  Scotland \n       99        55        90       100       177 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Définition de la variable de classe\nclasse_variable <- \"Class\"\n\n# Création de l'ensemble d'apprentissage et de l'ensemble de test\nset.seed(123) # Pour la reproductibilité\nindex <- createDataPartition(clean_data[[classe_variable]], p = 0.8, list = FALSE)\ndata_train <- clean_data[index, ]\ndata_test <- clean_data[-index, ]\n\n# Définition du contrôle de la validation croisée\ntrain_control <- trainControl(method = \"cv\", number = 5)  # Validation croisée à 5 plis\n\n# Ajustement du modèle PLS-DA\npls_model <- train(Class ~ ., data = data_train, method = \"pls\", trControl = train_control, preProc = c(\"center\", \"scale\"))\n```\n:::\n\n\nNous avons stratifié notre jeu de données en un ensemble d'apprentissage et un ensemble de test en utilisant la variable de classe \"Class\" comme référence pour notre prédiction. Cette division nous a permis de réserver 80% des données pour l'apprentissage et 20% pour l'évaluation. Pour garantir la reproductibilité, nous avons fixé une graine aléatoire. Les données sélectionnées ont été utilisées pour former l'ensemble d'apprentissage, tandis que les observations restantes ont constitué l'ensemble de test. Cette approche rigoureuse nous permettra d'évaluer la performance du modèle sur des données inconnues, assurant ainsi sa capacité à généraliser au-delà des données d'entraînement.\n\n## Modèle PLS-DA\n\nNous avons débuté en ajustant un modèle PLS-DA à l'aide de la méthode des moindres carrés partiels, une approche courante pour traiter des données multivariées telles que celles que nous avons utilisées. Ce modèle a été formé sur un ensemble d'apprentissage comprenant 418 échantillons et 20 prédicteurs, qui sont les éléments chimiques étudiés. Avant d'ajuster le modèle, nous avons centré et mis à l'échelle nos données pour garantir une comparaison juste entre les différentes variables.\n\nEn évaluant les performances du modèle, nous nous sommes concentrés sur deux principales métriques : l'exactitude (Accuracy) et le coefficient Kappa. L'exactitude mesure simplement le nombre de prédictions correctes par rapport au nombre total d'échantillons, tandis que le coefficient Kappa prend également en compte la possibilité de prédictions correctes dues au hasard.\n\nEn explorant différentes configurations de notre modèle, nous avons constaté que l'exactitude atteignait son maximum, dépassant les 85%, lorsque nous utilisions trois composantes latentes. Cela signifie que l'ajout d'une troisième composante latente a considérablement amélioré la capacité du modèle à prédire avec précision la classe à laquelle chaque échantillon appartient.\n\nPour mieux comprendre la qualité de nos prédictions, nous avons également visualisé les valeurs prédites par rapport aux valeurs réelles. Cette analyse visuelle nous a permis de confirmer que notre modèle était capable de discriminer efficacement entre les différentes classes, renforçant ainsi notre confiance dans ses performances.\n\nEn résumé, notre modèle PLS-DA a présenté des performances robustes, avec une exactitude dépassant les 85% lors de la validation croisée. Cela suggère que notre modèle est capable de classifier avec précision les échantillons de notre ensemble de test, ce qui est essentiel pour son utilisation dans des applications pratiques.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Affichage des résultats\nprint(pls_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPartial Least Squares \n\n418 samples\n 20 predictor\n  5 classes: 'Alaskan', 'Iceland-F', 'Iceland-W', 'Norway', 'Scotland' \n\nPre-processing: centered (20), scaled (20) \nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 335, 334, 335, 333, 335 \nResampling results across tuning parameters:\n\n  ncomp  Accuracy   Kappa    \n  1      0.4999150  0.3001568\n  2      0.6699453  0.5504397\n  3      0.8563616  0.8079397\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was ncomp = 3.\n```\n\n\n:::\n:::\n\n\n## Qualité prédictive du modèle\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visualisation de la performance du modèle\nplot(pls_model)\n```\n\n::: {.cell-output-display}\n![](UntitledQMD_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\nmodel=pls_model\n\n# Prédictions sur les données de test\npredictions <- predict(model, newdata = data_test)\n\n# Matrice de confusion\nconf_matrix <- table(predictions, data_test$Class)\nprint(conf_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           \npredictions Alaskan Iceland-F Iceland-W Norway Scotland\n  Alaskan        19         0         0      0        0\n  Iceland-F       0         3         0      0        1\n  Iceland-W       0         0        18      0        0\n  Norway          0         0         0     14        0\n  Scotland        0         8         0      6       34\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calcul de la précision\naccuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\nprint(paste(\"Accuracy:\", accuracy))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Accuracy: 0.854368932038835\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calcul du rappel (recall)\nrecall <- ifelse(rowSums(conf_matrix) == 0, 0, diag(conf_matrix) / rowSums(conf_matrix))\nprint(paste(\"Recall:\", mean(recall)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Recall: 0.891666666666667\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Calcul du score F1\nprecision <- ifelse(colSums(conf_matrix) == 0, 0, diag(conf_matrix) / colSums(conf_matrix))\nf1_score <- 2 * precision * recall / (precision + recall)\nf1_score <- ifelse(is.nan(f1_score), 0, f1_score)\nprint(paste(\"F1 Score:\", mean(f1_score)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"F1 Score: 0.808561304039688\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Identification des variables importantes\nimportance <- varImp(model)\nprint(importance)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\npls variable importance\n\n  variables are sorted by maximum importance across the classes\n   Alaskan Iceland-F Iceland-W Norway Scotland\nLi 100.000   52.0291    15.497 25.536   18.905\nB   98.505   73.0845    29.044 33.718   32.829\nCo  96.684   29.7344    18.953 21.950   16.758\nFe  58.308   34.5963    39.616 25.179   33.271\nCd  38.493   57.6616    43.966 28.827   41.665\nCs  49.781   19.7080    32.947 19.255   25.720\nCu  48.331    6.5322    24.046 13.738   16.774\nMo   2.339   48.0290     9.614 12.140   16.564\nSe  39.108   34.8579    46.696 25.347   38.799\nNi  45.962    1.5089     1.502  5.393    0.000\nV   19.252   44.3271    13.504 14.516   18.063\nRb  35.831   28.1526    33.454 19.510   28.212\nMn  20.278   34.0469    27.672 17.111   25.811\nZn  24.049    3.3185    31.936 12.930   22.278\nAs  26.266   26.3490    19.507 13.706   18.324\nTa  21.809    2.4185    12.359  6.331    8.440\nSr  16.507    2.9853     7.342  4.274    5.187\nAl  11.179   14.0218    15.568  8.416   13.395\nNb  14.738    0.9783     5.779  3.197    3.721\nCr  12.711    1.6006     7.509  3.640    5.116\n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualisation de l'importance des variables\nplot(importance)\n```\n\n::: {.cell-output-display}\n![](UntitledQMD_files/figure-html/unnamed-chunk-7-2.png){width=672}\n:::\n:::\n\n\nLa matrice de confusion est un outil essentiel pour évaluer la performance d'un modèle de classification comme le PLS-DA. Elle présente les résultats des prédictions du modèle par rapport aux classes réelles dans le jeu de test. Chaque cellule de la matrice représente le nombre d'observations pour lesquelles le modèle a prédit une classe spécifique (colonnes) par rapport à la classe réelle (lignes). Par exemple, si nous considérons la première ligne de la matrice, elle indique que le modèle a correctement classé 19 échantillons comme étant de la classe 'Alaskan', sans aucune erreur de classification pour les autres classes.\n\nL'exactitude (accuracy) est une mesure globale de la performance du modèle, calculée comme le rapport entre le nombre total de prédictions correctes et le nombre total d'observations dans le jeu de test. Une exactitude élevée, comme celle observée ici à environ 85.4%, indique que le modèle a réussi à prédire correctement la grande majorité des échantillons.\n\nLe rappel (recall) est une mesure de la capacité du modèle à identifier correctement les observations positives parmi toutes les observations réellement positives. Il est calculé comme le rapport entre le nombre de vrais positifs et la somme des vrais positifs et des faux négatifs. Un rappel élevé, tel que celui observé ici à environ 89.2%, indique que le modèle a une bonne capacité à rappeler les vraies observations positives.\n\nLe score F1 est une mesure combinée de la précision et du rappel du modèle, calculée comme la moyenne harmonique de ces deux métriques. Il tient compte à la fois des faux positifs et des faux négatifs. Un score F1 élevé, comme celui obtenu ici à environ 80.9%, suggère un bon équilibre entre la précision et le rappel du modèle.\n\nEn conclusion, les résultats de la matrice de confusion, de l'exactitude, du rappel et du score F1 indiquent que le modèle PLS-DA a des performances solides sur les données de test, avec une capacité satisfaisante à prédire correctement les classes des échantillons.\n\n## Interprétation du modèle ajusté\n\nL'analyse de l'interprétation du modèle PLS-DA révèle les éléments chimiques les plus pertinents pour la discrimination entre les différentes classes. Ces éléments sont classés en fonction de leur importance maximale à travers les différentes classes. Par exemple, le lithium (Li) est identifié comme étant le plus important pour discriminer la classe 'Alaskan', tandis que le bore (B) est crucial pour la classe 'Iceland-F'. Les valeurs attribuées à chaque élément indiquent leur contribution relative à la discrimination des classes, les valeurs plus élevées reflétant une contribution plus significative. Le graphique représente visuellement cette importance des variables pour chaque classe, où les barres plus hautes correspondent à une plus grande importance dans la discrimination de la classe correspondante.\n\nCette analyse permet ainsi d'identifier les éléments chimiques clés influençant la classification des saumons entre sauvage et d'élevage, fournissant ainsi de précieuses informations pour comprendre les compositions permettant la différenciation des échantillons.",
    "supporting": [
      "UntitledQMD_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}