---
title: "Analyse comparative de la spectrométrie du saumon de consommation"
author: "Paul Nestour"
date: "2024-05-16"
categories: [Dossier]
abstract: "Ce dossier a été rédigé dans le cadre du cours 'Modélisation avec des variables latentes' pendant notre première année de Master ECA."
---

## Introduction et démarche

L'étude initiale, issue de la publication "Data fusion and multivariate analysis for food authenticity analysis", avait pour objectif d'établir un modèle permettant de déterminer l'authenticité du saumon en fonction de son origine géographique et de son mode d'élevage. Pour ce faire, les chercheurs se sont appuyés sur une base de données constituée de 521 échantillons de saumon provenant de fournisseurs de quatre pays différents (Alaska, Écosse, Norvège et Islande), avec des méthodes de production sauvage ou d'élevage, chaque pays ayant ses spécificités propres.[^1]

[^1]: Hong, Y., Birse, N., Quinn, B., Li, Y., Jia, W., McCarron, P., Wu, D., Rosas da Silva, G., Vanhaecke, L., van Ruth, S., & Elliott, C. T.(2023).Data fusion and multivariate analysis for food authenticity analysis.Nature Communications, 14, Article 3309. https://doi.org/10.1038/s41467-023-38382-z

Ainsi, les chercheurs ont utilisé la spectrométrie de masse à plasma à couplage inductif (ICP-MS), une des techniques spectrométriques les plus importantes. Sa sensibilité extrêmement élevée et une large plage dynamique linéaire permettent l'analyse simultanée des composants principaux et des ultra-traces. Cette technique est capable d'analyser des éléments de Li à U et peut être appliquée aux solutions et aux solides. Son utilisation permet donc l’analyse quantitative d'éléments mineurs et est utilisée dans un large panel de processus industriels et agroalimentaires : qualification des matières premières, sécurité des produits, recherche et développement, contrôle de la production, analyse des défaillances, etc.[^2]

[^2]: https://www.euro\ins.fr/materials-and-engineering-sciences/nos-techniques/icp-ms/

La démarche suivie dans cette analyse a été méthodique, impliquant plusieurs étapes clés pour aboutir à une interprétation cohérente des résultats. Tout d'abord, une analyse descriptive du jeu de données partiel a été réalisée, comprenant 20 éléments chimiques au lieu des 37 initiaux. Les variables des éléments chimiques ont été renommées et normalisées entre 0 et 1. Cette première analyse consistait en la visualisation des statistiques de base des variables (Min, Q1, médiane, Q3, max et moyenne), de leurs valeurs atypiques ou des potentielles valeurs manquantes, ainsi qu’à l’observation des corrélations entre les variables. Les résultats ont été interprétés pour identifier les tendances et les relations entre les variables.

Ensuite, le jeu de données a été divisé en deux ensembles : un ensemble d'apprentissage et un ensemble de test, en fonction de la variable de classe, et le jeu de test est réservé exclusivement à l'évaluation de la performance du modèle. On a procédé à l'ajustement d'un modèle de prédiction. En parallèle, un modèle PLS-DA a été ajusté en utilisant la méthode des moindres carrés partiels avec une validation croisée à 5 plis. Les résultats de la validation croisée ont été minutieusement analysés pour sélectionner le nombre optimal de composantes latentes. La performance du modèle a été évaluée en termes d'exactitude, de kappa et d'autres métriques, tandis que sa qualité prédictive a été évaluée en utilisant la matrice de confusion, la précision, le rappel et le score F1 sur l'ensemble de test. De plus, les variables importantes pour la discrimination entre les classes ont été identifiées à partir de l'importance des variables dans le modèle PLS-DA. Tous ces résultats ont ensuite été visualisés pour faciliter leur interprétation.

En conclusion, cette approche méthodique et exhaustive a permis d'explorer et d'analyser en profondeur les données ICP-MS Raw, en mettant en lumière les modèles, les tendances et les relations entre les variables. Les conclusions tirées fournissent une base solide pour comprendre et interpréter les mécanismes sous-jacents ainsi que les facteurs influençant les différentes classes présentes dans les données.

```{r, output=FALSE}
# Chargement des packages nécessaires
install.packages("lattice")
library(readr)
library(dplyr)
library(ggplot2)
library(caret)
library(pls)
library(tidyr)
library(tidyverse)

# Lecture du fichier CSV
ICPMS_Raw_data <- read_csv("./ICPMS.csv")

# Conversion de la variable 'Class' en facteur
ICPMS_Raw_data$Class <- as.factor(ICPMS_Raw_data$Class)

# Sélection des 20 éléments restants
selected_elements <- c("7  Li  [ No Gas ]", "11  B  [ No Gas ]", "27  Al  [ He ]", "51  V  [ He ]", "52  Cr  [ He ]", "55  Mn  [ He ]", "56  Fe  [ He ]", "59  Co  [ He ]", "60  Ni  [ He ]", "63  Cu  [ He ]", "66  Zn  [ He ]", "75  As  [ He ]", "78  Se  [ He ]", "85  Rb  [ He ]", "88  Sr  [ He ]", "93  Nb  [ He ]", "95  Mo  [ He ]", "111  Cd  [ He ]", "133  Cs  [ He ]", "181  Ta  [ He ]")

# Sélectionner les colonnes spécifiées
selected_data <- ICPMS_Raw_data[, c("Class", selected_elements)]

# Renommer les colonnes
names(selected_data)[-1] <- c("Li", "B", "Al", "V", "Cr", "Mn", "Fe", "Co", "Ni", "Cu", "Zn", "As", "Se", "Rb", "Sr", "Nb", "Mo", "Cd", "Cs", "Ta")

# Sélection des colonnes
selected_data <- ICPMS_Raw_data %>%
  select(Class, all_of(selected_elements)) %>% 
  rename(
    Li = `7  Li  [ No Gas ]`,
    B = `11  B  [ No Gas ]`,
    Al = `27  Al  [ He ]`,
    V = `51  V  [ He ]`,
    Cr = `52  Cr  [ He ]`,
    Mn = `55  Mn  [ He ]`,
    Fe = `56  Fe  [ He ]`,
    Co = `59  Co  [ He ]`,
    Ni = `60  Ni  [ He ]`,
    Cu = `63  Cu  [ He ]`,
    Zn = `66  Zn  [ He ]`,
    As = `75  As  [ He ]`,
    Se = `78  Se  [ He ]`,
    Rb = `85  Rb  [ He ]`,
    Sr = `88  Sr  [ He ]`,
    Nb = `93  Nb  [ He ]`,
    Mo = `95  Mo  [ He ]`,
    Cd = `111  Cd  [ He ]`,
    Cs = `133  Cs  [ He ]`,
    Ta = `181  Ta  [ He ]`
  )

# Sélection des colonnes à normaliser
columns_to_normalize <- c("Li", "B", "Al", "V", "Cr", "Mn", "Fe", "Co", "Ni", "Cu", "Zn", "As", "Se", "Rb", "Sr", "Nb", "Mo", "Cd", "Cs", "Ta")

# Création d'une fonction pour la normalisation min-max
min_max_normalize <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}

# Appliquer la fonction de normalisation min-max à chaque colonne sélectionnée
normalized_data <- selected_data %>%
  mutate(across(all_of(columns_to_normalize), min_max_normalize))

# Nettoyage des données (exemple : supprimer les lignes avec des valeurs manquantes)
clean_data <- na.omit(normalized_data)
```

## Statistiques descriptives

Le jeu de données comprend 20 éléments chimiques, pour lesquels des statistiques descriptives ont été calculées. Les valeurs ont été normalisées pour rendre les variables comparables, révélant ainsi des distributions distinctes pour chaque variable. Dans l'ensemble, les distributions semblent être orientées vers le bas, suggérant une concentration relativement faible des éléments chimiques. De plus, il y a une présence notable de valeurs aberrantes potentielles, ce qui peut nécessiter une attention particulière lors de l'analyse.

```{r}
#Statistiques récapitulatives
summary(clean_data)

# Boxplots et moyennes des variables numériques 
clean_data |>
     pivot_longer(
      cols = where(is.numeric)
    ) |>
    ggplot() +
    aes(y = value) +
    facet_wrap(~ name, scales = "free_y") +
    geom_boxplot() +
    theme_light()
```

## Analyse des Corrélations

```{r}
#Corrélations entre les variables
cor_matrix <- cor(clean_data[, -1]) # Exclure la variable de classe
corrplot::corrplot(cor_matrix, method = "circle")
```

```{r}
# Sélectionner les corrélations supérieures à 0.8
high_corr <- which(cor_matrix > 0.8 & cor_matrix < 1, arr.ind = TRUE)

# Afficher les paires de variables corrélées
high_corr_pairs <- data.frame(row = rownames(cor_matrix)[high_corr[,1]],
                              col = colnames(cor_matrix)[high_corr[,2]],
                              corr_value = cor_matrix[high_corr])
high_corr_pairs
```

Les résultats de l’analyse des corrélations suggèrent également qu'il existe des corrélations significatives entre certaines paires de variables. Par exemple, la corrélation des éléments chimiques Se et Zn est de 0.82, celle des éléments chimiques Cs et Rb est de 0.87, et celle des éléments chimiques Ta et Nb est de 0.94. Ces fortes corrélations peuvent indiquer une relation chimique ou géologique commune entre ces éléments. Ces résultats peuvent servir de base pour des analyses plus avancées ou pour formuler des hypothèses à explorer davantage dans notre étude.

## Découpage du Jeu de Données

```{r}
# Distribution de la variable Class
table(clean_data$Class)

# Définition de la variable de classe
classe_variable <- "Class"

# Création de l'ensemble d'apprentissage et de l'ensemble de test
set.seed(123) # Pour la reproductibilité
index <- createDataPartition(clean_data[[classe_variable]], p = 0.8, list = FALSE)
data_train <- clean_data[index, ]
data_test <- clean_data[-index, ]

# Définition du contrôle de la validation croisée
train_control <- trainControl(method = "cv", number = 5)  # Validation croisée à 5 plis

# Ajustement du modèle PLS-DA
pls_model <- train(Class ~ ., data = data_train, method = "pls", trControl = train_control, preProc = c("center", "scale"))
```

Nous avons stratifié notre jeu de données en un ensemble d'apprentissage et un ensemble de test en utilisant la variable de classe "Class" comme référence pour notre prédiction. Cette division nous a permis de réserver 80% des données pour l'apprentissage et 20% pour l'évaluation. Pour garantir la reproductibilité, nous avons fixé une graine aléatoire. Les données sélectionnées ont été utilisées pour former l'ensemble d'apprentissage, tandis que les observations restantes ont constitué l'ensemble de test. Cette approche rigoureuse nous permettra d'évaluer la performance du modèle sur des données inconnues, assurant ainsi sa capacité à généraliser au-delà des données d'entraînement.

## Modèle PLS-DA

Nous avons débuté en ajustant un modèle PLS-DA à l'aide de la méthode des moindres carrés partiels, une approche courante pour traiter des données multivariées telles que celles que nous avons utilisées. Ce modèle a été formé sur un ensemble d'apprentissage comprenant 418 échantillons et 20 prédicteurs, qui sont les éléments chimiques étudiés. Avant d'ajuster le modèle, nous avons centré et mis à l'échelle nos données pour garantir une comparaison juste entre les différentes variables.

En évaluant les performances du modèle, nous nous sommes concentrés sur deux principales métriques : l'exactitude (Accuracy) et le coefficient Kappa. L'exactitude mesure simplement le nombre de prédictions correctes par rapport au nombre total d'échantillons, tandis que le coefficient Kappa prend également en compte la possibilité de prédictions correctes dues au hasard.

En explorant différentes configurations de notre modèle, nous avons constaté que l'exactitude atteignait son maximum, dépassant les 85%, lorsque nous utilisions trois composantes latentes. Cela signifie que l'ajout d'une troisième composante latente a considérablement amélioré la capacité du modèle à prédire avec précision la classe à laquelle chaque échantillon appartient.

Pour mieux comprendre la qualité de nos prédictions, nous avons également visualisé les valeurs prédites par rapport aux valeurs réelles. Cette analyse visuelle nous a permis de confirmer que notre modèle était capable de discriminer efficacement entre les différentes classes, renforçant ainsi notre confiance dans ses performances.

En résumé, notre modèle PLS-DA a présenté des performances robustes, avec une exactitude dépassant les 85% lors de la validation croisée. Cela suggère que notre modèle est capable de classifier avec précision les échantillons de notre ensemble de test, ce qui est essentiel pour son utilisation dans des applications pratiques.

```{r}
# Affichage des résultats
print(pls_model)
```

## Qualité prédictive du modèle
```{r}
# Visualisation de la performance du modèle
plot(pls_model)

model=pls_model

# Prédictions sur les données de test
predictions <- predict(model, newdata = data_test)

# Matrice de confusion
conf_matrix <- table(predictions, data_test$Class)
print(conf_matrix)

# Calcul de la précision
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(paste("Accuracy:", accuracy))

# Calcul du rappel (recall)
recall <- ifelse(rowSums(conf_matrix) == 0, 0, diag(conf_matrix) / rowSums(conf_matrix))
print(paste("Recall:", mean(recall)))

# Calcul du score F1
precision <- ifelse(colSums(conf_matrix) == 0, 0, diag(conf_matrix) / colSums(conf_matrix))
f1_score <- 2 * precision * recall / (precision + recall)
f1_score <- ifelse(is.nan(f1_score), 0, f1_score)
print(paste("F1 Score:", mean(f1_score)))

# Identification des variables importantes
importance <- varImp(model)
print(importance)

# Visualisation de l'importance des variables
plot(importance)
```

La matrice de confusion est un outil essentiel pour évaluer la performance d'un modèle de classification comme le PLS-DA. Elle présente les résultats des prédictions du modèle par rapport aux classes réelles dans le jeu de test. Chaque cellule de la matrice représente le nombre d'observations pour lesquelles le modèle a prédit une classe spécifique (colonnes) par rapport à la classe réelle (lignes). Par exemple, si nous considérons la première ligne de la matrice, elle indique que le modèle a correctement classé 19 échantillons comme étant de la classe 'Alaskan', sans aucune erreur de classification pour les autres classes.

L'exactitude (accuracy) est une mesure globale de la performance du modèle, calculée comme le rapport entre le nombre total de prédictions correctes et le nombre total d'observations dans le jeu de test. Une exactitude élevée, comme celle observée ici à environ 85.4%, indique que le modèle a réussi à prédire correctement la grande majorité des échantillons.

Le rappel (recall) est une mesure de la capacité du modèle à identifier correctement les observations positives parmi toutes les observations réellement positives. Il est calculé comme le rapport entre le nombre de vrais positifs et la somme des vrais positifs et des faux négatifs. Un rappel élevé, tel que celui observé ici à environ 89.2%, indique que le modèle a une bonne capacité à rappeler les vraies observations positives.

Le score F1 est une mesure combinée de la précision et du rappel du modèle, calculée comme la moyenne harmonique de ces deux métriques. Il tient compte à la fois des faux positifs et des faux négatifs. Un score F1 élevé, comme celui obtenu ici à environ 80.9%, suggère un bon équilibre entre la précision et le rappel du modèle.

En conclusion, les résultats de la matrice de confusion, de l'exactitude, du rappel et du score F1 indiquent que le modèle PLS-DA a des performances solides sur les données de test, avec une capacité satisfaisante à prédire correctement les classes des échantillons.

## Interprétation du modèle ajusté

L'analyse de l'interprétation du modèle PLS-DA révèle les éléments chimiques les plus pertinents pour la discrimination entre les différentes classes. Ces éléments sont classés en fonction de leur importance maximale à travers les différentes classes. Par exemple, le lithium (Li) est identifié comme étant le plus important pour discriminer la classe 'Alaskan', tandis que le bore (B) est crucial pour la classe 'Iceland-F'. Les valeurs attribuées à chaque élément indiquent leur contribution relative à la discrimination des classes, les valeurs plus élevées reflétant une contribution plus significative. Le graphique représente visuellement cette importance des variables pour chaque classe, où les barres plus hautes correspondent à une plus grande importance dans la discrimination de la classe correspondante.

Cette analyse permet ainsi d'identifier les éléments chimiques clés influençant la classification des saumons entre sauvage et d'élevage, fournissant ainsi de précieuses informations pour comprendre les compositions permettant la différenciation des échantillons.